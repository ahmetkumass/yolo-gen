{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloGen Demo\n",
    "\n",
    "Object Detection + VLM Description Pipeline\n",
    "\n",
    "**3 Usage Modes:**\n",
    "- **YOLO Only** - Object detection\n",
    "- **VLM Only** - Image description (with or without bbox)\n",
    "- **YOLO + VLM** - Detection + Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Your model paths (update these)\n",
    "YOLO_WEIGHTS = \"../runs/your_experiment/yolo/weights/best.pt\"\n",
    "VLM_ADAPTER = \"../runs/your_experiment/vlm/best\"\n",
    "TEST_IMAGE = \"path/to/your/image.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YOLO Only\n",
    "\n",
    "Just object detection, no VLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yologen.core.predictor import YOLOPredictor\n",
    "\n",
    "yolo = YOLOPredictor(weights=YOLO_WEIGHTS)\n",
    "results = yolo.predict(TEST_IMAGE)\n",
    "\n",
    "for det in results[0]['detections']:\n",
    "    print(f\"{det['class_name']}: {det['confidence']:.2f} | bbox: {det['bbox']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. VLM Only\n",
    "\n",
    "Image description without YOLO detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from yologen.core.predictor import VLMPredictor\n\n# Default: loads box_color and box_thickness from training config\nvlm = VLMPredictor(vlm_adapter=VLM_ADAPTER, vlm_precision=\"4bit\")\n\n# Or override manually (use same as training for best results!)\n# vlm = VLMPredictor(\n#     vlm_adapter=VLM_ADAPTER,\n#     vlm_precision=\"4bit\",\n#     box_color=(255, 0, 0),   # RGB Red\n#     box_thickness=3,\n# )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case A: You provide bbox coordinates -> we draw the red box\n",
    "answer = vlm.predict(\n",
    "    image=TEST_IMAGE,\n",
    "    bbox=[100, 100, 300, 300],  # [x1, y1, x2, y2]\n",
    "    question=\"What is in the red marked area?\",\n",
    ")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case B: Image already has red box drawn -> just ask question\n",
    "answer = vlm.predict(\n",
    "    image=\"image_with_box_already.jpg\",\n",
    "    bbox=None,  # No bbox = don't draw\n",
    "    question=\"What is in the red marked area?\",\n",
    ")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case C: Ask about whole image (no box)\n",
    "answer = vlm.predict(\n",
    "    image=TEST_IMAGE,\n",
    "    question=\"What do you see in this image?\",\n",
    ")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. YOLO + VLM (Unified)\n",
    "\n",
    "Detection + Description in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from yologen.core.predictor import UnifiedPredictor\n\n# Default: loads box_color and box_thickness from training config\npredictor = UnifiedPredictor(\n    yolo_weights=YOLO_WEIGHTS,\n    vlm_adapter=VLM_ADAPTER,\n    vlm_precision=\"4bit\",\n    # box_color=(255, 0, 0),   # Optional: override (RGB)\n    # box_thickness=3,         # Optional: override\n)\n\nresults = predictor.predict(\n    source=TEST_IMAGE,\n    vlm_question=\"What is in the red marked area?\",\n)\n\nfor det in results[0]['detections']:\n    print(f\"[{det['class_name']}] {det['confidence']:.2f}\")\n    print(f\"  VLM: {det['vlm_answer']}\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(TEST_IMAGE)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for det in results[0]['detections']:\n",
    "    x1, y1, x2, y2 = [int(v) for v in det['bbox']]\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "    cv2.putText(img, det['class_name'], (x1, y1-10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Advanced Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "results = predictor.predict(\n",
    "    source=TEST_IMAGE,\n",
    "    vlm_question=\"What is in the red marked area?\",\n",
    "    save=True,\n",
    "    save_dir=\"./output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing\n",
    "from pathlib import Path\n",
    "\n",
    "for img_path in Path(\"./images\").glob(\"*.jpg\"):\n",
    "    results = predictor.predict(source=str(img_path))\n",
    "    print(f\"{img_path.name}: {len(results[0]['detections'])} detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom questions\n",
    "questions = [\n",
    "    \"What is in the red marked area?\",\n",
    "    \"Is this dangerous?\",\n",
    "    \"Describe this object.\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    results = predictor.predict(source=TEST_IMAGE, vlm_question=q)\n",
    "    answer = results[0]['detections'][0]['vlm_answer'] if results[0]['detections'] else \"No detection\"\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}